{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f2fc07-8b8f-4aa0-844d-3fe43f57855e",
   "metadata": {},
   "source": [
    "## Download all reports from Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49df479e-686f-4392-96c1-dd599d08acda",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3219,
    "lastExecutedAt": 1706539309078,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Webbrowser automation\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.wait import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n# Time\nimport time\n# To work with files\nimport wget\nimport pyreadstat\nimport os\n# Data wrangling\nimport pandas as pd \nimport numpy as np\n# Visualization\nimport seaborn as sns"
   },
   "outputs": [],
   "source": [
    "# Webbrowser automation\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# Time\n",
    "import time\n",
    "# To work with files\n",
    "import wget\n",
    "import pyreadstat\n",
    "import os\n",
    "# Data wrangling\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from utils.utils import sign_in_manager\n",
    "from utils.utils import get_survey_list\n",
    "from utils.utils import generate_excel_data\n",
    "from utils.utils import download_raw_data\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d8802e9-4559-4eb1-b5e1-b8529d5c2436",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": null,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 357,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report for 524065\n",
      "Error token found!\t Resubmitting form again\n",
      "Report for survey 524065 is being generated\n",
      "Generating report for 368438\n",
      "Report for survey 368438 is being generated\n",
      "Generating report for 625173\n",
      "Report for survey 625173 is being generated\n",
      "Generating report for 431924\n",
      "Report for survey 431924 is being generated\n",
      "Generating report for 597650\n",
      "Report for survey 597650 is being generated\n",
      "Generating report for 165836\n",
      "Report for survey 165836 is being generated\n",
      "Generating report for 828252\n",
      "Report for survey 828252 is being generated\n",
      "Generating report for 952146\n",
      "Report for survey 952146 is being generated\n",
      "Getting the raw data file link for 524065\n",
      "100% [........................................................................] 13254071 / 13254071File data//Raw Data 524065 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 368438\n",
      "100% [..........................................................................] 6473902 / 6473902File data//Raw Data 368438 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 625173\n",
      "100% [..........................................................................] 7978288 / 7978288File data//Raw Data 625173 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 431924\n",
      "100% [..........................................................................] 7043701 / 7043701File data//Raw Data 431924 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 597650\n",
      "100% [..........................................................................] 7693859 / 7693859File data//Raw Data 597650 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 165836\n",
      "100% [..........................................................................] 7157055 / 7157055File data//Raw Data 165836 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 828252\n",
      "100% [........................................................................] 10972118 / 10972118File data//Raw Data 828252 2024-03-13.xlsx was downloaded\n",
      "Getting the raw data file link for 952146\n",
      "100% [..........................................................................] 6268053 / 6268053File data//Raw Data 952146 2024-03-13.xlsx was downloaded\n",
      "Exception in webdriver: cannot use a string pattern on a bytes-like object\n",
      "Quitting webdriver session\n"
     ]
    }
   ],
   "source": [
    "# Remove every file in the data folder\n",
    "files = os.listdir(os.environ[\"DATA_DIR\"])\n",
    "for file in files:\n",
    "    if os.path.isfile(os.environ[\"DATA_DIR\"] + file):\n",
    "        print(f\"Removing file {os.environ['DATA_DIR'] + file}\")\n",
    "        os.remove(os.environ[\"DATA_DIR\"] + file)\n",
    "try:\n",
    "    # Connect to the remote webdriver\n",
    "    options = webdriver.EdgeOptions()\n",
    "    # options.headless = True\n",
    "    driver = webdriver.Remote(os.environ[\"REMOTE_SERVER\"], options = options)\n",
    "\n",
    "    # Sign into Manager using the credentials\n",
    "    sign_in_manager(driver, os.environ[\"SYNO_EMAIL\"], os.environ[\"SYNO_PASSWORD\"])\n",
    "    survey_list = get_survey_list(driver, 4700)\n",
    "\n",
    "    # Generate the raw data for all surveys\n",
    "    for survey_id in survey_list[\"Id\"]:\n",
    "        print(f\"Generating report for {survey_id}\")\n",
    "        generate_excel_data(driver, survey_id)\n",
    "\n",
    "    # Get all download links for lastest files generated\n",
    "    exported_file_links = []\n",
    "    for survey_id in survey_list[\"Id\"]:\n",
    "        print(f\"Getting the raw data file link for {survey_id}\")\n",
    "        exported_file_links.append(download_raw_data(driver, survey_id))\n",
    "\n",
    "    # Take links and download all files\n",
    "    for file in exported_file_links:\n",
    "        downloaded_file = wget.download(file, \"data/\")\n",
    "        print(f\"File {downloaded_file} was downloaded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Exception in webdriver: {e}\")\n",
    "finally:\n",
    "    print(\"Quitting webdriver session\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8c3d3a",
   "metadata": {},
   "source": [
    "## Generated the merged report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8069a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file data/Raw Data 368438 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 368438 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 431924 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 431924 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 524065 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 524065 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 952146 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 952146 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 597650 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 597650 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 165836 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 165836 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 828252 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 828252 2024-03-13.xlsx merged\n",
      "Processing file data/Raw Data 625173 2024-03-13.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kenneth/.local/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/Raw Data 625173 2024-03-13.xlsx merged\n",
      "All files were merged!\n"
     ]
    }
   ],
   "source": [
    "data, meta = pyreadstat.read_sav(\"merged_data.sav\")\n",
    "data.drop(data.index, axis = \"index\", inplace = True)\n",
    "\n",
    "for file in glob.glob(os.environ[\"DATA_DIR\"] + '*.xlsx'):\n",
    "    print(f\"Processing file {file}\")\n",
    "    chunk = pd.read_excel(file)\n",
    "    chunk.drop(0, axis = \"index\", inplace = True)\n",
    "    new_column_names = ['guid','ip','panelist_id','identity_id','last_page','version','mode','locale','started','completed','loi','status','source','device','g','year_of_birth','postal_code']\n",
    "    chunk.columns = new_column_names + list(chunk.columns[len(new_column_names):])\n",
    "\n",
    "    # Replace the CONTROL2 code with a custom one depending on survey ID\n",
    "    if file.__contains__(\"524065\"): # Sweden\n",
    "        chunk[\"CONTROL2\"] = 1\n",
    "    elif file.__contains__(\"828252\"): # USA\n",
    "        chunk[\"CONTROL2\"] = 2\n",
    "    elif file.__contains__(\"597650\"): # Singapore\n",
    "        chunk[\"CONTROL2\"] = 3\n",
    "    elif file.__contains__(\"165836\"): # UK\n",
    "        chunk[\"CONTROL2\"] = 4\n",
    "    elif file.__contains__(\"431924\"): # Germany\n",
    "        chunk[\"CONTROL2\"] = 5\n",
    "    elif file.__contains__(\"625173\"): # India\n",
    "        chunk[\"CONTROL2\"] = 6\n",
    "    elif file.__contains__(\"368438\"): # Japan\n",
    "        chunk[\"CONTROL2\"] = 7\n",
    "    elif file.__contains__(\"952146\"): # China\n",
    "        chunk[\"CONTROL2\"] = 8\n",
    "    data = pd.concat([data, chunk], axis = \"index\")\n",
    "    print(f\"File {file} merged\")\n",
    "print(\"All files were merged!\")\n",
    "\n",
    "# Create a new column for the week number\n",
    "data[\"week\"] = pd.to_datetime(data[\"completed\"]).dt.isocalendar().week\n",
    "# Uppercase postcodes in A3\n",
    "data[\"A3\"] = data[\"A3\"].str.upper()\n",
    "\n",
    "# Read the master list of codes and brands (all countries)\n",
    "brands = pd.read_excel(\"4162 Codebook.xlsx\", sheet_name = \"BRANDS\", dtype=str)\n",
    "# Read the codebook for each brand (in English)\n",
    "brands_codebook = pd.read_excel(\"4162 Codebook.xlsx\", sheet_name=\"BRANDS_CODEBOOK\", dtype=str)\n",
    "\n",
    "# Read the list of statements per country\n",
    "statements = pd.read_excel(\"4162 Codebook.xlsx\", sheet_name=\"STATEMENTS\", dtype=str)\n",
    "# Read the codebook for the statements (in English)\n",
    "statements_codebook = pd.read_excel(\"4162 Codebook.xlsx\", sheet_name=\"STATEMENTS_CODEBOOK\", dtype=str)\n",
    "\n",
    "# Remove unicode characters\n",
    "brands['Brand name'] = brands['Brand name'].apply(lambda x: str(x).replace('\\xa0', ' '))\n",
    "statements['Statement'] = statements['Statement'].apply(lambda x: str(x).replace('\\xa0', ' '))\n",
    "\n",
    "# Get the list of codes and their brands\n",
    "brand_labels = {}\n",
    "for item in brands.to_dict(orient = \"split\")[\"data\"]:\n",
    "    brand_labels[item[1]] = item[0]\n",
    "\n",
    "# Get the list of codes and their labels in English\n",
    "brand_codes = {}\n",
    "for item in brands_codebook.to_dict(\"split\")[\"data\"]:\n",
    "    brand_codes[item[0]] = item[1]\n",
    "\n",
    "# Get the list of codes and their statements\n",
    "statement_labels = {}\n",
    "for item in statements.to_dict(orient = \"split\")[\"data\"]:\n",
    "    statement_labels[item[1]] = item[0]\n",
    "    \n",
    "# Get the list of codes and their labels in English\n",
    "statement_codes = {}\n",
    "for item in statements_codebook.to_dict(orient = \"split\")[\"data\"]:\n",
    "    statement_codes[item[0]] = item[1]\n",
    "\n",
    "for i in range(0, 10):\n",
    "    # Replace the statement label by their respective codes (in each language)\n",
    "    data[f\"FILTER3_{i}\"].replace(statement_labels, inplace=True)\n",
    "    meta.variable_value_labels[f\"FILTER3_{i}\"] = statement_codes\n",
    "\n",
    "for i in range(0, 30):\n",
    "    # Replace the brand labels by their respective codes\n",
    "    data[f\"FILTER_{i}\"].replace(brand_labels, inplace=True)\n",
    "    meta.variable_value_labels[f\"FILTER_{i}\"] = brand_codes\n",
    "\n",
    "for i in range(0, 8):\n",
    "    data[f\"FILTER2_{i}\"].replace(brand_labels, inplace=True)\n",
    "    meta.variable_value_labels[f\"FILTER2_{i}\"] = brand_codes\n",
    "\n",
    "data.to_excel(\"4700 Lynxeye merged data.xlsx\", index = False)\n",
    "# pyreadstat.write_sav(data, \"4700 Lynxeye merged data.sav\", variable_value_labels = meta.variable_value_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c38d7f",
   "metadata": {},
   "source": [
    "## Reconciliate unmatched responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39ffcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
